{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "lUz4raRuX-Xc",
        "outputId": "0e6bcfc7-d9cf-4c4e-cbcf-9a8ed330b60b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "mount failed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         )\n\u001b[0;32m--> 272\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"mahmoudalforawi/igneous-metamorphic-sedimentary-rocks-and-minerals\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nxm5x_ur31na",
        "outputId": "e284fa28-133e-4061-f812-09548c2906f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.0).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/mahmoudalforawi/igneous-metamorphic-sedimentary-rocks-and-minerals?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 349M/349M [00:13<00:00, 28.1MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/mahmoudalforawi/igneous-metamorphic-sedimentary-rocks-and-minerals/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"shlokjain69/rock-classification\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b887wNq64AKj",
        "outputId": "6d3e42e6-182a-46b3-f3b2-7613b6984542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.0).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/shlokjain69/rock-classification?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 167M/167M [00:06<00:00, 25.0MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/shlokjain69/rock-classification/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"cristianminas/geochemical-variations-in-igneous-rocks-mining\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5CfTM914IS5",
        "outputId": "bc45aa4f-e3db-435d-8ebf-17e5d007b8ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.0).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/cristianminas/geochemical-variations-in-igneous-rocks-mining?dataset_version_number=5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 151k/151k [00:00<00:00, 470kB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/cristianminas/geochemical-variations-in-igneous-rocks-mining/versions/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "\n",
        "# Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„ØªÙŠ Ø¸Ù‡Ø±Øª Ù„Ùƒ ÙÙŠ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª\n",
        "path_rocks_minerals = \"/root/.cache/kagglehub/datasets/mahmoudalforawi/igneous-metamorphic-sedimentary-rocks-and-minerals/versions/1\"\n",
        "path_classification = \"/root/.cache/kagglehub/datasets/shlokjain69/rock-classification/versions/1\"\n",
        "\n",
        "# Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Data Augmentation) Ù„Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… Ø§Ù„Ø­ÙØ¸ Ø¨Ù„ Ø§Ù„ÙÙ‡Ù…\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2, # 20% Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.3\n",
        ")\n",
        "\n",
        "# Ù…Ù„Ø§Ø­Ø¸Ø©: Ø³Ù†Ø¨Ø¯Ø£ Ø¨Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø£ÙƒØ¨Ø± (Rocks and Minerals)\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    path_rocks_minerals,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    path_rocks_minerals,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "print(f\"ğŸ”¥ ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {train_generator.num_classes} ØªØµÙ†ÙŠÙ ØµØ®Ø±ÙŠ ÙˆÙ…Ø¹Ø¯Ù†ÙŠ.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMphT_zZ4bwK",
        "outputId": "a95e893a-4f24-46d0-d720-466460b2334d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6963 images belonging to 1 classes.\n",
            "Found 1740 images belonging to 1 classes.\n",
            "ğŸ”¥ ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ 1 ØªØµÙ†ÙŠÙ ØµØ®Ø±ÙŠ ÙˆÙ…Ø¹Ø¯Ù†ÙŠ.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø«Ø§Ù†ÙŠ\n",
        "geochem_path = \"/root/.cache/kagglehub/datasets/cristianminas/geochemical-variations-in-igneous-rocks-mining/versions/5\"\n",
        "\n",
        "# Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù„Ù Ø§Ù„Ù€ CSV Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ø¬Ù„Ø¯ ÙˆÙ‚Ø±Ø§Ø¡ØªÙ‡\n",
        "csv_files = [f for f in os.listdir(geochem_path) if f.endswith('.csv')]\n",
        "if csv_files:\n",
        "    df_geochem = pd.read_csv(os.path.join(geochem_path, csv_files[0]))\n",
        "    print(\"ğŸ“Š ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬ÙŠÙˆÙƒÙŠÙ…ÙŠØ§Ø¦ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­!\")\n",
        "    print(df_geochem.head()) # Ø¹Ø±Ø¶ Ø£ÙˆÙ„ 5 Ø£Ø³Ø·Ø± Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙƒÙŠÙ…ÙŠØ§Ø¦ÙŠØ©\n",
        "else:\n",
        "    print(\"â„¹ï¸ Ø§Ù„Ù…Ø¬Ù„Ø¯ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ù„ÙØ§Øª Ø¨Ø±Ù…Ø¬ÙŠØ©ØŒ Ø³Ù†Ø³ØªØ®Ø¯Ù…Ù‡Ø§ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ù„Ø§Ø­Ù‚Ø§Ù‹.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkBPMMp34rhq",
        "outputId": "3e87f3ec-56cc-41ad-fd3c-6da60b8af043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Š ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬ÙŠÙˆÙƒÙŠÙ…ÙŠØ§Ø¦ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­!\n",
            "  rock_name      long      lat  SiO2n  TiO2n  Al2O3n  FeO*n  MnOn   MgOn  \\\n",
            "0    Basalt -122.5850  46.2300  47.77   1.33   15.38   9.59  0.17  10.76   \n",
            "1    Basalt -122.5806  46.2436  47.94   1.28   15.22   9.60  0.18  10.87   \n",
            "2    Basalt -122.5925  46.2036  51.50   1.12   16.04   8.77  0.15   9.49   \n",
            "3    Basalt -122.5797  46.2144  45.66   1.60   14.87   9.90  0.17   9.81   \n",
            "4    Basalt -122.5839  46.2100  48.24   1.34   15.91  10.16  0.17  10.06   \n",
            "\n",
            "    CaOn  Na2On  K2On P2O5n  \n",
            "0  11.28   2.69  0.62  0.41  \n",
            "1  11.39   2.17  0.96  0.38  \n",
            "2   9.80   2.64  0.33  0.16  \n",
            "3  13.09   3.09  0.96  0.84  \n",
            "4  10.78   2.51  0.56  0.26  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import gdown\n",
        "import os\n",
        "\n",
        "# 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø· (Ø§Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¢Ø®Ø±)\n",
        "# Ù‚Ù…Øª Ø¨Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù€ ID Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ø°ÙŠ Ø£Ø±Ø³Ù„ØªÙ‡\n",
        "old_model_url = 'https://drive.google.com/uc?id=1tOsn8F5Bspr4xYiM5LmoA4Dj0EAbIJ8v'\n",
        "output_model_name = 'previous_rock_model.h5'\n",
        "\n",
        "if not os.path.exists(output_model_name):\n",
        "    print(\"ğŸš€ Ø¬Ø§Ø±ÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù…Ù† Ø§Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ù‚Ø¯ÙŠÙ…...\")\n",
        "    gdown.download(old_model_url, output_model_name, quiet=False)\n",
        "\n",
        "# 2. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙˆØªØ¬Ù‡ÙŠØ²Ù‡ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©\n",
        "try:\n",
        "    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø³Ø§Ø¨Ù‚\n",
        "    old_model = tf.keras.models.load_model(output_model_name)\n",
        "\n",
        "    # Ø³Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù€ Base (Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ) Ù…Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù‚Ø¯ÙŠÙ…\n",
        "    # ÙˆÙ†Ø¶ÙŠÙ Ù„Ù‡ Ø·Ø¨Ù‚Ø© Ø£Ø®ÙŠØ±Ø© ØªÙ†Ø§Ø³Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª ÙÙŠ Ø§Ù„Ø¯Ø§ØªØ§ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© (349MB + 167MB)\n",
        "    base_layers = old_model.layers[:-1] # Ù†Ø£Ø®Ø° ÙƒÙ„ Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ù…Ø§ Ø¹Ø¯Ø§ Ø§Ù„Ø£Ø®ÙŠØ±Ø©\n",
        "\n",
        "    model = tf.keras.Sequential(base_layers)\n",
        "    model.add(tf.keras.layers.Dense(train_generator.num_classes, activation='softmax'))\n",
        "\n",
        "    print(f\"âœ… ØªÙ… Ø¯Ù…Ø¬ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù‚Ø¯ÙŠÙ…. Ø³ÙŠØªÙ… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø¢Ù† Ø¹Ù„Ù‰ {train_generator.num_classes} ØµÙ†ÙØ§Ù‹ Ø¬Ø¯ÙŠØ¯Ø§Ù‹.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø±Ø¨Ø· Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù‚Ø¯ÙŠÙ…ØŒ Ø³Ù†Ø¨Ø¯Ø£ Ø¨ØªØ¯Ø±ÙŠØ¨ Ù‡ÙŠÙƒÙ„ Ø¬Ø¯ÙŠØ¯: {e}\")\n",
        "    # ÙƒÙˆØ¯ Ø¨Ø¯ÙŠÙ„ ÙÙŠ Ø­Ø§Ù„ ÙØ´Ù„ Ø§Ù„Ø±Ø¨Ø· Ø§Ù„ØªÙ‚Ù†ÙŠ\n",
        "    base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
        "    base_model.trainable = False\n",
        "    model = tf.keras.Sequential([\n",
        "        base_model,\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\n",
        "        tf.keras.layers.Dense(256, activation='relu'),\n",
        "        tf.keras.layers.Dense(train_generator.num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "# 3. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ (Global Rock Expert)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 4. Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…Ø·ÙˆØ± (15 Ø¯ÙˆØ±Ø© Ù„Ø¶Ù…Ø§Ù† Ø§Ø³ØªÙŠØ¹Ø§Ø¨ Ø§Ù„Ø¯Ø§ØªØ§ Ø§Ù„Ø¶Ø®Ù…Ø©)\n",
        "print(\"âš™ï¸ Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØµÙ‚Ù„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ (Global Training)...\")\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=15\n",
        ")\n",
        "\n",
        "# 5. Ø­ÙØ¸ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ \"Ø§Ù„Ø¹Ù…Ù„Ø§Ù‚\" ÙÙŠ Ø­Ø³Ø§Ø¨Ùƒ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø¹Ù„Ù‰ Ø§Ù„Ø¯Ø±Ø§ÙŠÙ\n",
        "model.save('global_rock_expert_v2.h5')\n",
        "# ØªØ£ÙƒØ¯ Ù…Ù† Ø±Ø¨Ø· Ø­Ø³Ø§Ø¨Ùƒ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø¨Ø§Ù„Ø¯Ø±Ø§ÙŠÙ Ø£ÙˆÙ„Ø§Ù‹\n",
        "!cp global_rock_expert_v2.h5 /content/drive/MyDrive/global_rock_expert_v2.h5\n",
        "\n",
        "print(\"ğŸ’¾ Ù…Ø¨Ø±ÙˆÙƒ! Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø£ØµØ¨Ø­ ÙÙŠ Ø­Ø³Ø§Ø¨Ùƒ Ø§Ù„Ø­Ø§Ù„ÙŠ Ø¨Ù†Ø¬Ø§Ø­.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJ6nIz8k4zy0",
        "outputId": "df114562-e8f2-477a-ad08-e64ffa376b87"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ Ø¬Ø§Ø±ÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù…Ù† Ø§Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ù‚Ø¯ÙŠÙ…...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1tOsn8F5Bspr4xYiM5LmoA4Dj0EAbIJ8v\n",
            "To: /content/previous_rock_model.h5\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11.4M/11.4M [00:00<00:00, 13.9MB/s]\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âš ï¸ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø±Ø¨Ø· Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù‚Ø¯ÙŠÙ…ØŒ Ø³Ù†Ø¨Ø¯Ø£ Ø¨ØªØ¯Ø±ÙŠØ¨ Ù‡ÙŠÙƒÙ„ Ø¬Ø¯ÙŠØ¯: All layers added to a Sequential model should have unique names. Name 'dense' is already the name of a layer in this model. Update the `name` argument to pass a unique name.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "âš™ï¸ Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØµÙ‚Ù„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ (Global Training)...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/ops/nn.py:944: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/losses/losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m218/218\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m468s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 2/15\n",
            "\u001b[1m218/218\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m548s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 3/15\n",
            "\u001b[1m218/218\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 4/15\n",
            "\u001b[1m218/218\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 5/15\n",
            "\u001b[1m218/218\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 6/15\n",
            "\u001b[1m218/218\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m451s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 7/15\n",
            "\u001b[1m218/218\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m504s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 8/15\n",
            "\u001b[1m218/218\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m448s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 9/15\n",
            "\u001b[1m218/218\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 10/15\n",
            "\u001b[1m218/218\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m504s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 11/15\n",
            "\u001b[1m218/218\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 12/15\n",
            "\u001b[1m218/218\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 13/15\n",
            "\u001b[1m218/218\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m499s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 14/15\n",
            "\u001b[1m218/218\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m510s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 15/15\n",
            "\u001b[1m218/218\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot create regular file '/content/drive/MyDrive/global_rock_expert_v2.h5': No such file or directory\n",
            "ğŸ’¾ Ù…Ø¨Ø±ÙˆÙƒ! Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø£ØµØ¨Ø­ ÙÙŠ Ø­Ø³Ø§Ø¨Ùƒ Ø§Ù„Ø­Ø§Ù„ÙŠ Ø¨Ù†Ø¬Ø§Ø­.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Ø±Ø¨Ø· Ø¬ÙˆØ¬Ù„ Ø¯Ø±Ø§ÙŠÙ\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø®Ø§Øµ Ø¨Ù…Ø´Ø§Ø±ÙŠØ¹Ùƒ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹\n",
        "project_folder = '/content/drive/MyDrive/Sulaiman_AI_Projects'\n",
        "if not os.path.exists(project_folder):\n",
        "    os.makedirs(project_folder)\n",
        "    print(f\"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø¬Ø¯ÙŠØ¯: {project_folder}\")"
      ],
      "metadata": {
        "id": "65nFR1dchtkj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56f783fd-2ce0-4f85-b021-4f667dbb88b6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø¬Ø¯ÙŠØ¯: /content/drive/MyDrive/Sulaiman_AI_Projects\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯ Ø­ÙØ¸Ù‡\n",
        "model_name = 'global_rock_expert_v2.h5'\n",
        "\n",
        "# Ø­ÙØ¸ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙÙŠ Ø°Ø§ÙƒØ±Ø© Colab Ø£ÙˆÙ„Ø§Ù‹\n",
        "model.save(model_name)\n",
        "\n",
        "# Ù†Ù‚Ù„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø®ØµØµ ÙÙŠ Ø¬ÙˆØ¬Ù„ Ø¯Ø±Ø§ÙŠÙ\n",
        "import shutil\n",
        "destination_path = os.path.join(project_folder, model_name)\n",
        "sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "Mtr-wBvpjZM5",
        "outputId": "92e8f2ea-83cf-442a-9450-f3e14ad167d1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'sh' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2840105208.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdestination_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0msh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'sh' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯ Ø­ÙØ¸Ù‡\n",
        "model_name = 'Rock_Mineral_Expert_Model.h5'\n",
        "\n",
        "# Ø­ÙØ¸ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙÙŠ Ø°Ø§ÙƒØ±Ø© Colab Ø£ÙˆÙ„Ø§Ù‹\n",
        "model.save(model_name)\n",
        "\n",
        "# Ù†Ù‚Ù„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø®ØµØµ ÙÙŠ Ø¬ÙˆØ¬Ù„ Ø¯Ø±Ø§ÙŠÙ\n",
        "import shutil\n",
        "destination_path = os.path.join(project_folder, model_name)\n",
        "shutil.copy(model_name, destination_path)\n",
        "\n",
        "print(f\"ğŸš€ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­ ÙÙŠ Ø§Ù„Ø¯Ø±Ø§ÙŠÙ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§Ø±: {destination_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2YbKOBrkpg7",
        "outputId": "828ffa2c-7afd-4578-9831-88742783adbf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­ ÙÙŠ Ø§Ù„Ø¯Ø±Ø§ÙŠÙ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§Ø±: /content/drive/MyDrive/Sulaiman_AI_Projects/Rock_Mineral_Expert_Model.h5\n"
          ]
        }
      ]
    }
  ]
}